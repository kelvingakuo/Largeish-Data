services:
  minio-server: # MinIO server to act as S3 storage
    image: quay.io/minio/minio
    container_name: minio
    environment:
      - MINIO_ROOT_USER=admin
      - MINIO_ROOT_PASSWORD=password
      - MINIO_DOMAIN=minio
    networks:
     iceberg_net:
       aliases:
         - warehouse.minio
    ports:
      - 9003:9001 #UI
      - 9004:9000 #API
    volumes:
      - minio_data:/data
    command: ["server", "/data", "--console-address", ":9001"]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://127.0.0.1:9000/minio/health/ready"]
      interval: 5s
      timeout: 60s
      retries: 5
      start_period: 20s

  minio-client: # MinIO client to setup the warehouse bucket on MinIO server
    depends_on:
      - minio-server
    image: minio/mc
    container_name: minio_client
    networks:
     iceberg_net:
    environment:
      - AWS_ACCESS_KEY_ID=admin
      - AWS_SECRET_ACCESS_KEY=password
      - AWS_REGION=us-east-1
    entrypoint: |
      /bin/sh -c "
      until (/usr/bin/mc alias set minio http://minio:9000 admin password) do echo '...waiting...' && sleep 1; done;
      /usr/bin/mc rm -r minio/warehouse;
      /usr/bin/mc mb minio/warehouse;
      /usr/bin/mc policy set public minio/warehouse;
      tail -f /dev/null
      "

  # rest-catalog: # REST catalog for testing. Replace with a real backend e.g. Gravitino, Nessie
  #   depends_on:
  #     - minio-client
  #   image: apache/iceberg-rest-fixture
  #   container_name: iceberg-rest-test
  #   networks:
  #    iceberg_net:
  #   ports:
  #     - 8181:8181
  #   environment:
  #     - AWS_ACCESS_KEY_ID=admin
  #     - AWS_SECRET_ACCESS_KEY=password
  #     - AWS_REGION=us-east-1
  #     - CATALOG_WAREHOUSE=s3://warehouse/
  #     - CATALOG_IO__IMPL=org.apache.iceberg.aws.s3.S3FileIO
  #     - CATALOG_S3_ENDPOINT=http://minio:9004

  nessie-rest-catalog: # Nessie REST catalog
    depends_on:
      - minio-client
    image: ghcr.io/projectnessie/nessie
    container_name: nessie-rest
    ports:
      - 19120:19120 # UI
      - 9002:9000 # API
    networks:
     iceberg_net:

  trino: # Trino SQL Engine with Iceberg connector
    depends_on:
      # - rest-catalog
      - nessie-rest-catalog
    image: trinodb/trino
    container_name: trino
    networks:
     iceberg_net:
    ports:
      - 8082:8080
    volumes:
      # - trino/trino_rest_iceberg_catalog.properties:/etc/trino/catalog/iceberg.properties
      # - trino/trino_nessie_iceberg_catalog.properties:/etc/trino/catalog/iceberg.properties
      - trino/trino_nessie_s3_iceberg_catalog.properties:/etc/trino/catalog/iceberg.properties
      - minio_data:/data
    environment:
      - AWS_ACCESS_KEY_ID
      - AWS_SECRET_ACCESS_KEY
      - AWS_REGION=us-east-1
    # trino://admin@host.docker.internal:8082/iceberg -- The correct connection URI
      
  dbt: # dbt for data transformation. Uses Trino as the SQL connector
    depends_on:
      - trino
    build: 
      context: ./dbt
      dockerfile: DOCKERFILE
    container_name: dbt_trino
    volumes:
      - ./dbt:/usr/app/dbt
      - ./dbt/profiles.yml:/root/.dbt/profiles.yml
    environment:
      DBT_PROFILES_DIR: /root/.dbt
    entrypoint: ["tail", "-f", "/dev/null"]
    networks:
     iceberg_net:

    # docker exec -it dbt_trino bash
    # dbt seed
    # docker exec -it trino trino
    # select count(*) from iceberg.dwh_bronze.users;

  prefect-server: # Prefect server for orchestration
    depends_on:
      - dbt
    build: 
      context: ./prefect
      dockerfile: DOCKERFILE
    container_name: prefect_server
    environment:
      - PREFECT_UI_URL=http://127.0.0.1:4200/api
      - PREFECT_API_URL=http://127.0.0.1:4200/api
      - PREFECT_SERVER_API_HOST=0.0.0.0
    ports:
      - 4200:4200
    volumes:
      - minio_data:/data
    networks:
     iceberg_net:

  apache-superset: # Apache Superset for data visualization
    build: 
      context: ./superset
      dockerfile: DOCKERFILE
    container_name: superset
    ports:
      - 8088:8088
    environment:
        - ADMIN_USERNAME=admin
        - ADMIN_EMAIL=admin@superset.com
        - ADMIN_PASSWORD=password
    volumes:
      - minio_data:/data
    networks:
     iceberg_net:

  # docker compose up apache-superset --build apache-superset # Force these containers to rebuild

  kafka: # Kafka message broker in KRaft mode (no Zookeeper) (https://romanglushach.medium.com/the-evolution-of-kafka-architecture-from-zookeeper-to-kraft-f42d511ba242)
    image: confluentinc/cp-kafka:latest
    container_name: kafka
    ports:
      - 9092:9092 # External traffic
      - 29092:29092 # Internal Docker network traffic
      - 9093:9093 # KRaft controller traffic
    environment:
      # KRaft settings
      - KAFKA_NODE_ID=1
      - KAFKA_BROKER_ID=1
      - KAFKA_PROCESS_ROLES=broker,controller # The node is both a broker and a controller (KRaft mode). With Zookeeper, the node would just be a broker.
      - KAFKA_CONTROLLER_QUORUM_VOTERS=1@kafka:9093
      # Listeners
      - KAFKA_LISTENERS=INTERNAL://0.0.0.0:29092,EXTERNAL://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093 # Where Kafka listens for bootstrap connections (Clients connect to bootstrap, get metadata, then reconnect using advertised listeners)
      - KAFKA_ADVERTISED_LISTENERS=INTERNAL://kafka:29092,EXTERNAL://localhost:9092 # What clients use to connect to Kafka
      - KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      - KAFKA_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_INTER_BROKER_LISTENER_NAME=INTERNAL
    volumes:
      - ./kafka-data:/var/lib/kafka/data # Store data locally on host machine
    networks:
     kafka_net:

  kafka-ui: # Kafka UI to monitor Kafka topics
    image: kafbat/kafka-ui:latest # provectuslabs/kafka-ui:latest is no longer mantained
    container_name: kafka-cluster-ui
    ports:
      - "8080:8080"
    environment:
      - KAFKA_CLUSTERS_0_NAME=kafka-local-cluster
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka:29092
    depends_on:
      - kafka
    networks:
     kafka_net:

  binance-kafka-producer: # Kafka producer for sending messages to Kafka topics with Binance data
    depends_on:
      - kafka
    build: 
      context: ./kafka
      dockerfile: BINANCE_DOCKERFILE
    container_name: binance_kafka_producer
    networks:
     kafka_net:

  coinbase-kafka-producer: # Kafka producer for sending messages to Kafka topics with Coinbase data
    depends_on:
      - kafka
    build: 
      context: ./kafka
      dockerfile: COINBASE_DOCKERFILE
    container_name: coinbase_kafka_producer
    networks:
     kafka_net:

  kraken-kafka-producer: # Kafka producer for sending messages to Kafka topics with Kraken data
    depends_on:
      - kafka
    build: 
      context: ./kafka
      dockerfile: KRAKEN_DOCKERFILE
    container_name: kraken_kafka_producer
    networks:
     kafka_net:

volumes:
  minio_data:
    driver: local

networks:
  iceberg_net:
    name: iceberg-network
  kafka_net:
    name: kafka-network